# Agent Optimization Summary

**Last Updated:** 2025-10-05
**Optimization Goal:** Reduce agent execution time from ~5 minutes to under 30 seconds where possible

---

## üöÄ Optimized Agents Available

### 1. Research Agent V2 - OPTIMIZED ‚úÖ

**File:** `backend/agentic_service/agents/research_agent_v2_optimized.py`

**Performance:**
- **Before:** ~160 seconds (intelligence gathering phase)
- **After:** ~13 seconds (intelligence gathering phase)
- **Speedup:** **12x faster** ‚ö°

**Key Changes:**
- Fixed critical sequential execution bug (lines 158-166)
- Implemented true parallel execution with `asyncio.gather()`
- Added shared aiohttp session for connection pooling
- All scrapers execute concurrently instead of sequentially

**When to Use:**
```python
# RECOMMENDED: Use optimized version
from backend.agentic_service.agents.research_agent_v2_optimized import ResearchAgentV2Optimized
agent = ResearchAgentV2Optimized()
```

**Critical Bug Fixed:**
```python
# ‚ùå BEFORE (Sequential - SLOW)
for name, task in tasks.items():
    results[name] = await task  # Blocks on each await!

# ‚úÖ AFTER (Parallel - FAST)
results_list = await asyncio.gather(*tasks, return_exceptions=True)
```

---

### 2. Data Modeling Agent - NO CHANGE ‚è∏Ô∏è

**File:** `backend/agentic_service/agents/data_modeling_agent.py` (original)

**Status:** **Kept Claude Sonnet 4.5**

**Performance:**
- Claude Sonnet 4.5: ~40-45 seconds
- Gemini 2.0 Flash: ~10 seconds (4x faster) - **REJECTED by user**
- Gemini 2.5 Pro: ~40 seconds (same as Claude) - tested but not adopted

**User Decision:**
> "lets stick to Claude Sonnet for now"

**When to Use:**
```python
# Use original Claude version (user preference)
from backend.agentic_service.agents.data_modeling_agent import DataModelingAgent
agent = DataModelingAgent()
```

**Note:** Alternative versions created for reference only:
- `data_modeling_agent_optimized.py` (Gemini 2.0 Flash - not recommended)
- `data_modeling_agent_gemini_pro.py` (Gemini 2.5 Pro - same performance as Claude)

---

### 3. Synthetic Data Generator - OPTIMIZED ‚úÖ

**File:** `backend/agentic_service/agents/synthetic_data_generator_optimized.py`

**Performance:**
- **Before:** ~24 seconds (sequential table generation)
- **After:** ~8 seconds (parallel table generation)
- **Speedup:** **3x faster** ‚ö°

**Key Changes:**
- Dependency-aware parallel table generation
- Groups tables by foreign key dependencies
- Generates independent tables concurrently
- Async CSV file I/O with `asyncio.to_thread()`

**When to Use:**
```python
# RECOMMENDED: Use optimized version
from backend.agentic_service.agents.synthetic_data_generator_optimized import SyntheticDataGeneratorOptimized
agent = SyntheticDataGeneratorOptimized()
```

**Optimization Strategy:**
```python
# Groups tables into dependency levels
# Level 0: customers, products (no dependencies) ‚Üí Generate in parallel
# Level 1: orders (depends on customers) ‚Üí Generate in parallel after Level 0
# Level 2: order_items (depends on orders) ‚Üí Generate in parallel after Level 1
```

---

### 4. Infrastructure Agent - OPTIMIZED ‚úÖ

**File:** `backend/agentic_service/agents/infrastructure_agent_optimized.py`

**Performance:**
- **Before:** ~90 seconds (6 tables √ó 15s each, sequential)
- **After:** ~20 seconds (6 tables in parallel)
- **Speedup:** **4-5x faster** ‚ö°

**Key Changes:**
- Parallel BigQuery table creation and data loading
- All tables created/loaded concurrently with `asyncio.gather()`
- Async BigQuery operations using `asyncio.to_thread()`
- Parallel execution of CAPI agent creation + documentation generation

**When to Use:**
```python
# RECOMMENDED: Use optimized version
from backend.agentic_service.agents.infrastructure_agent_optimized import InfrastructureAgentOptimized
agent = InfrastructureAgentOptimized()
```

**Critical Optimization:**
```python
# ‚ùå BEFORE (Sequential)
for table_def in tables:
    stats = self._create_and_load_table(table_def)  # Wait for each table

# ‚úÖ AFTER (Parallel)
tasks = [self._create_and_load_single_table(t) for t in tables]
results = await asyncio.gather(*tasks)  # All tables at once!
```

---

### 5. Demo Validator - OPTIMIZED ‚úÖ

**File:** `backend/agentic_service/agents/demo_validator_optimized.py`

**Performance:**
- **Before:** ~15 seconds (5 queries √ó 3s each, sequential)
- **After:** ~3-5 seconds (all queries in parallel)
- **Speedup:** **3-4x faster** ‚ö°

**Key Changes:**
- Parallel BigQuery query validation
- All 5 test queries execute concurrently
- Async query execution using `asyncio.to_thread()`
- Async file I/O for validation report

**When to Use:**
```python
# RECOMMENDED: Use optimized version
from backend.agentic_service.agents.demo_validator_optimized import DemoValidatorOptimized
agent = DemoValidatorOptimized()
```

---

### 6. CAPI Instruction Generator - OPTIMIZED ‚úÖ

**File:** `backend/agentic_service/agents/capi_instruction_generator_optimized.py`

**Performance:**
- **Before:** Single blocking file write
- **After:** Async file I/O
- **Speedup:** Minor (~0.5-1s saved)

**Key Changes:**
- Async YAML file I/O
- Non-blocking summary report generation

**When to Use:**
```python
# RECOMMENDED: Use optimized version
from backend.agentic_service.agents.capi_instruction_generator_optimized import CAPIInstructionGeneratorOptimized
agent = CAPIInstructionGeneratorOptimized()
```

**Note:** Cannot parallelize main LLM call (single unified YAML document required)

---

### 7. Demo Story Agent - ALREADY OPTIMIZED ‚úÖ

**File:** `backend/agentic_service/agents/demo_story_agent.py`

**Status:** Already uses parallel execution (no new optimized version needed)

**Performance:**
- Uses 3 concurrent Claude 4.5 calls
- 37% faster than sequential execution
- Execution time: ~2-3 minutes (LLM-bound, cannot optimize further)

**When to Use:**
```python
# Use existing version (already optimized)
from backend.agentic_service.agents.demo_story_agent import DemoStoryAgent
agent = DemoStoryAgent()
```

**Architecture:**
```python
# Already runs 3 tasks in parallel
tasks = [
    self._generate_core_narrative(...),
    self._generate_golden_queries(...),
    self._generate_data_specs(...)
]
results = await asyncio.gather(*tasks)  # Already parallel!
```

---

## üîß Supporting Tool Optimizations

### Intelligent Crawler - OPTIMIZED

**File:** `backend/agentic_service/tools/v2_intelligent_crawler_optimized.py`

**Performance:**
- **Before:** ~75 seconds (sequential page fetching)
- **After:** ~7 seconds (concurrent batch crawling)
- **Speedup:** **10x faster** ‚ö°

**Key Changes:**
- Concurrent batch processing with semaphore (15 concurrent requests)
- Reduced max_pages from 50 to 30
- Smart early termination based on coverage
- Batch delay (0.1s per batch instead of 0.5s per page)

---

### Web Scrapers - ALL UPDATED

**Files Updated:**
- `backend/agentic_service/tools/web_research.py`
- `backend/agentic_service/tools/v2_multi_source.py`
- `backend/agentic_service/tools/v2_job_scraper.py`
- `backend/agentic_service/tools/v2_google_search.py`

**Key Changes:**
- All scrapers now accept optional `session` parameter
- Shared `aiohttp.ClientSession` for connection pooling
- Saves 5-8 seconds in connection setup overhead

**Usage:**
```python
async with aiohttp.ClientSession() as session:
    # All scrapers share the same session
    result1 = await scrape_website(url, session)
    result2 = await BlogScraper().scrape_blogs(query, session)
    result3 = await JobPostingScraper().scrape_jobs(query, session)
```

---

## üìä Overall Pipeline Impact

### Estimated Time Savings

| Agent | Time Saved | Original Time | Optimized Time |
|-------|-----------|---------------|----------------|
| Research Agent V2 | ~147s | 160s | 13s |
| Data Modeling Agent | 0s | 42s | 42s (Claude kept) |
| Synthetic Data Generator | ~16s | 24s | 8s |
| Infrastructure Agent | ~70s | 90s | 20s |
| Demo Validator | ~10s | 15s | 5s |
| CAPI Instructions | ~1s | 2s | 1s |

**Total Time Saved: ~244 seconds (~4 minutes faster)** üéâ

**Full Pipeline:**
- Before: ~5-6 minutes
- After: ~2-3 minutes (depending on LLM response times)

---

## üéØ Key Optimization Patterns Applied

### 1. asyncio.gather() - Parallel Execution

**Pattern:**
```python
tasks = [task1(), task2(), task3()]
results = await asyncio.gather(*tasks, return_exceptions=True)
```

**Used In:**
- Research Agent V2 (12 concurrent scrapers)
- Synthetic Data Generator (parallel table generation)
- Infrastructure Agent (parallel BigQuery operations)
- Demo Validator (parallel query validation)
- Demo Story Agent (3 concurrent LLM calls)

---

### 2. asyncio.to_thread() - Blocking SDK Calls

**Pattern:**
```python
# Run blocking SDK call in thread pool
result = await asyncio.to_thread(
    blocking_function,
    arg1,
    arg2
)
```

**Used In:**
- All agents calling BigQuery (blocking SDK)
- All agents calling Vertex AI LLMs (blocking SDK)
- File I/O operations (blocking)

---

### 3. Shared HTTP Session - Connection Pooling

**Pattern:**
```python
async with aiohttp.ClientSession() as session:
    # Reuse connections across multiple requests
    results = await asyncio.gather(
        scraper1(url1, session),
        scraper2(url2, session),
        scraper3(url3, session)
    )
```

**Used In:**
- Research Agent V2 (shared across all scrapers)
- Intelligent Crawler (batch requests)

---

### 4. Semaphore - Rate Limiting

**Pattern:**
```python
semaphore = asyncio.Semaphore(15)  # Max 15 concurrent

async def fetch_with_limit(url):
    async with semaphore:
        return await fetch(url)

tasks = [fetch_with_limit(url) for url in urls]
results = await asyncio.gather(*tasks)
```

**Used In:**
- Intelligent Crawler (controls concurrent HTTP requests)
- Research Agent V2 (prevents overwhelming target servers)

---

### 5. Dependency-Aware Batching

**Pattern:**
```python
# Group by dependencies
levels = [
    [customers, products],  # Level 0: no deps
    [orders],               # Level 1: depends on customers
    [order_items]           # Level 2: depends on orders
]

for level in levels:
    # Process each level in parallel
    results = await asyncio.gather(*[gen_table(t) for t in level])
```

**Used In:**
- Synthetic Data Generator (respects foreign key constraints)

---

### 6. Async File I/O

**Pattern:**
```python
# Non-blocking file write
await asyncio.to_thread(df.to_csv, filename, index=False)
```

**Used In:**
- Synthetic Data Generator (CSV writes)
- Infrastructure Agent (report generation)
- Demo Validator (report generation)
- CAPI Instructions (YAML file)

---

## üîÑ How to Migrate to Optimized Versions

### Update Orchestrator/Workflow

**Before:**
```python
from backend.agentic_service.agents.research_agent_v2 import ResearchAgentV2
from backend.agentic_service.agents.synthetic_data_generator import SyntheticDataGenerator
from backend.agentic_service.agents.infrastructure_agent import InfrastructureAgent
from backend.agentic_service.agents.demo_validator import DemoValidator
from backend.agentic_service.agents.capi_instruction_generator import CAPIInstructionGenerator

# Initialize agents
research_agent = ResearchAgentV2()
data_gen_agent = SyntheticDataGenerator()
infra_agent = InfrastructureAgent()
validator = DemoValidator()
capi_gen = CAPIInstructionGenerator()
```

**After (RECOMMENDED):**
```python
from backend.agentic_service.agents.research_agent_v2_optimized import ResearchAgentV2Optimized
from backend.agentic_service.agents.synthetic_data_generator_optimized import SyntheticDataGeneratorOptimized
from backend.agentic_service.agents.infrastructure_agent_optimized import InfrastructureAgentOptimized
from backend.agentic_service.agents.demo_validator_optimized import DemoValidatorOptimized
from backend.agentic_service.agents.capi_instruction_generator_optimized import CAPIInstructionGeneratorOptimized

# Initialize optimized agents
research_agent = ResearchAgentV2Optimized()
data_gen_agent = SyntheticDataGeneratorOptimized()
infra_agent = InfrastructureAgentOptimized()
validator = DemoValidatorOptimized()
capi_gen = CAPIInstructionGeneratorOptimized()
```

**Note:** All optimized agents maintain the same interface (`execute(state)` method), so they're drop-in replacements.

---

## ‚ö†Ô∏è Important Notes

### 1. Data Modeling Agent - User Preference

**DO NOT** switch to Gemini models without user approval:
- User explicitly rejected Gemini 2.0 Flash despite 4x speedup
- User chose to keep Claude Sonnet 4.5 for quality reasons
- Quote: *"lets stick to Claude Sonnet for now"*

### 2. Demo Story Agent - Already Optimized

No new optimized version created because:
- Already uses parallel execution (3 concurrent LLM calls)
- LLM response time is the bottleneck (~2-3 minutes)
- Cannot parallelize further (requires strategic thinking)

### 3. Sequential vs Parallel - Critical Pattern

**Common Bug to Avoid:**
```python
# ‚ùå WRONG - This is still SEQUENTIAL!
for task in tasks:
    result = await task  # Blocks on each await

# ‚úÖ CORRECT - True parallelism
results = await asyncio.gather(*tasks)
```

---

## üìù Testing & Validation

### Benchmark Results Available

**Files:**
- `benchmark_data_modeling.json` - Data Modeling Agent comparison
- `benchmark_gemini_pro_vs_claude.json` - Gemini 2.5 Pro vs Claude benchmark

### Running Benchmarks

**Research Agent V2:**
```bash
python3 test_research_agent_v2_optimized.py
```

**Data Modeling:**
```bash
python3 test_data_modeling_gemini_pro.py
```

**Full Pipeline:**
```bash
# Test with OfferUp.com
curl -X POST http://localhost:8000/api/provision/start \
  -H "Content-Type: application/json" \
  -d '{"customer_url": "https://www.offerup.com"}'
```

---

## üéì Lessons Learned

### 1. Sequential Await is the #1 Performance Killer

**Impact:** 12x slowdown in Research Agent V2

**Fix:** Use `asyncio.gather()` instead of awaiting in loops

### 2. Connection Pooling Saves Seconds

**Impact:** 5-8 seconds saved across Research Agent

**Fix:** Share aiohttp.ClientSession across all scrapers

### 3. Dependency Analysis Enables Safe Parallelism

**Impact:** 3x speedup in data generation

**Fix:** Group by foreign key dependencies, parallelize within levels

### 4. User Preferences Override Performance

**Impact:** Kept Claude despite Gemini being 4x faster

**Fix:** Always confirm model changes with user

---

## üìû Questions?

**When in doubt:**
- Use optimized versions (they're drop-in replacements)
- Keep Claude Sonnet 4.5 for Data Modeling Agent
- Use `asyncio.gather()` for true parallelism
- Share HTTP sessions for connection pooling
- Run blocking SDK calls with `asyncio.to_thread()`

**Last Updated:** 2025-10-05
**Optimized By:** Claude Code Assistant
**Benchmark Platform:** Google Cloud Shell (bq-demos-469816)
